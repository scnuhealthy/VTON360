seed: 42

model_path: "/GPUFS/sysu_gbli2_1/hzj/pretrained_models/stable-diffusion-v1-5"
vae_path: "/GPUFS/sysu_gbli2_1/hzj/pretrained_models/sd-vae-ft-mse"
clip_model_path: '/GPUFS/sysu_gbli2_1/hzj/pretrained_models/clip-vit-base-patch32'

# unet_path: "/GPUFS/sysu_gbli2_1/hzj/animate/checkpoints/thuman_tryon_mvattn_multi_1205/checkpoint-30000"
# pretrained_poseguider_path: "/GPUFS/sysu_gbli2_1/hzj/animate/checkpoints/thuman_tryon_mvattn_multi_1205/checkpoint-30000/pose.ckpt"
# pretrained_referencenet_path: '/GPUFS/sysu_gbli2_1/hzj/animate/checkpoints/thuman_tryon_mvattn_multi_1205/checkpoint-30000'

unet_path: "/GPUFS/sysu_gbli2_1/hzj/animate/checkpoints/mvhumannet_tryon_mvattn_multi_1205/checkpoint-40000"
pretrained_poseguider_path: "/GPUFS/sysu_gbli2_1/hzj/animate/checkpoints/mvhumannet_tryon_mvattn_multi_1205/checkpoint-40000/pose.ckpt"
pretrained_referencenet_path: '/GPUFS/sysu_gbli2_1/hzj/animate/checkpoints/mvhumannet_tryon_mvattn_multi_1205/checkpoint-40000'

out_dir: 'image_output_tryon_mvhumannet'

batch_size: 2
dataloader_num_workers: 4
guidance_scale: 2  # thuman:3 mvhumannet:2


# infer_data:
#   # dataroot: "/GPUFS/sysu_gbli2_1/hzj/render_data"
#   dataroot: "/GPUFS/sysu_gbli2_1/hzj/save_render_data_yw/"
#   # sample_size:  [512,384] # for 40G 256
#   sample_size:  [768,576]
#   clip_model_path: '/GPUFS/sysu_gbli2_1/hzj/pretrained_models/clip-vit-base-patch32'
#   is_train: false
#   mode: 'pair'
#   output_front: true

infer_data:
  # dataroot: "/GPUFS/sysu_gbli2_1/hzj/render_data"
  dataroot: "/GPUFS/sysu_gbli2_1/hzj/mvhumannet/"
  # sample_size:  [512,384] # for 40G 256
  sample_size:  [768,576]
  clip_model_path: '/GPUFS/sysu_gbli2_1/hzj/pretrained_models/clip-vit-base-patch32'
  is_train: false
  mode: 'pair'
  output_front: true

fusion_blocks: "full"
image_finetune: true
num_inference_steps: 30